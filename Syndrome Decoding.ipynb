{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syndrome Decoding and Incomplete Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mahan Madani - 99222092**\n",
    "\n",
    "Note: this file contains the answer to the both the Syndrome Decoding and Incomplete decoding projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "- [Preparations and Utility Functions](##-Preparations-and-Utility-Functions)\n",
    "- [Linear Block Code Class](##Linear-Block-Code-Class)\n",
    "- [Examples](##Examples)\n",
    "    - [Example 1](###Example-1)\n",
    "    - [Example 2](###Example-2)\n",
    "    - [Example 3](###Example-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Functions defined in this section are all used in the constructor of the Linear Block Code class. The block code is defined using a list of linearly independent vectors. All attributes of the code including the Generator and Parity matrices are set up using the initial vectors.\n",
    "\n",
    "* Note that for this project, I assumed all codes are binary and are craeted over GF(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a standardized generator matrix from in the form [I | A]\n",
    "\n",
    "def build_generator_matrix(vectors):\n",
    "    matrix = sp.Matrix(vectors)    \n",
    "    echelon_matrix, _ = matrix.rref(simplify=True)\n",
    "\n",
    "    echelon_matrix = [row for row in echelon_matrix.tolist() if any(row)]  # remove rows filled with 0\n",
    "    \n",
    "    return np.array(echelon_matrix, dtype=int) % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a standardized parity matrix in the form [B | I]\n",
    "\n",
    "def build_parity_matrix(generator_matrix):\n",
    "    k, n = generator_matrix.shape\n",
    "    redundancy_matrix = generator_matrix[:, k:]\n",
    "    \n",
    "    return np.concatenate([redundancy_matrix.T, np.identity(n-k, dtype=int)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum hamming distance of a code is equal to its minimum weight, so by using the `np.count_nonzero()` function we can calculate the minimum hamming distance by iterating over all of the code words and finding the smallest weight.\n",
    "\n",
    "The `minimum_hamming_dist` calculates the minimum Hamming distance of a linear block code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_hamming_dist(linear_code):\n",
    "    min_dist = linear_code.n\n",
    "    \n",
    "    for vector in linear_code.generate_codewords():\n",
    "        hamming_dist = np.count_nonzero(vector)\n",
    "        min_dist = hamming_dist if (hamming_dist < min_dist and hamming_dist > 0) else min_dist\n",
    "    \n",
    "    return min_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_coset_table()` function iterates over all possible binary values with maximum length n. They will then be partitioned using into cosets. `coset_table` maps each syndrome to its respective coset (which is the collection of all binary values with that specific syndrome value)\n",
    "\n",
    "\n",
    "Note that `coset_table` is a one-to-many mapping, meaning that it maps a syndrome to all members of a coset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coset_table(linear_code):\n",
    "    coset_table = dict()\n",
    "    \n",
    "    # generate all binary messages from 0 to 2^n\n",
    "    for i in range(2**linear_code.n):\n",
    "        codeword = np.array(list(map(int, bin(i)[2:].zfill(linear_code.n)))).tolist()\n",
    "        syndrome = linear_code.compute_syndrome(codeword)\n",
    "        \n",
    "        if syndrome in coset_table:\n",
    "            coset_table[syndrome].append(codeword)\n",
    "        else:\n",
    "            coset_table[syndrome] = [codeword]\n",
    "    \n",
    "    return coset_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_syndrome_table()` function creates a dictionary mapping each syndrome to the coset leader from the `coset_table`.\n",
    "\n",
    "Unlike `coset_table`, the `syndrome_table` dictionary uses one-to-one mapping, meaning that each syndrome is mapped to exactly one coset leader. The coset leader is chosen from the `coset_table`, the coset with the smallest weight is chosen as the leader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_syndrome_table(coset_table):\n",
    "    coset_leader_table = dict()\n",
    "\n",
    "    for syndrome in coset_table:\n",
    "        coset_leader = coset_table[syndrome][0]\n",
    "\n",
    "        for codeword in coset_table[syndrome]:\n",
    "            coset_leader = codeword if np.count_nonzero(codeword) < np.count_nonzero(coset_leader) else coset_leader\n",
    "\n",
    "        coset_leader_table[syndrome] = coset_leader\n",
    "\n",
    "    return coset_leader_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Block Code Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class is used to create linear block codes from a list of vectors.\n",
    "\n",
    "The constructor call many of the functions defined in the previous section to set various values and find the coset_table and the coset_leader_table.\n",
    "\n",
    "**Syndrom Decoding**: Codes made using this class can utilize syndrome values to detect errors and correct them. The syndrome table is generated using the coset table.\n",
    "\n",
    "**Incomplete Decoding**: Even if a code cannot be corrected, errors can still be detected in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearCode:\n",
    "    \n",
    "    def __init__(self, vectors):\n",
    "        self.G = build_generator_matrix(vectors)\n",
    "        self.H = build_parity_matrix(self.G)\n",
    "\n",
    "        self.k, self.n = self.G.shape\n",
    "        self.d = minimum_hamming_dist(self)\n",
    "        self.correction_thershold = (self.d - 1)//2     # The maximum number of error that can be corrected\n",
    "\n",
    "        self.coset_table = generate_coset_table(self)\n",
    "        self.syndrome_table = generate_syndrome_table(self.coset_table)  # Maps syndromes to coset leaders\n",
    "\n",
    "    \n",
    "    def generate_codewords(self):   # Generate all possible codewords from the generator matrix\n",
    "        codewords = []\n",
    "        for i in range(2**self.k):\n",
    "            message = np.array(list(map(int, bin(i)[2:].zfill(self.k))))  # generate all binary messages from 0 to 2^k\n",
    "            codeword = np.dot(message, self.G) % 2                        # find the encoded value of each binary message\n",
    "            codewords.append(codeword)\n",
    "            \n",
    "        return np.array(codewords)\n",
    "    \n",
    "    \n",
    "    def compute_syndrome(self, r) -> str:   # Compute the syndrome value of a received message. the value is stored as a string for later usage.\n",
    "        if len(r) == self.n:\n",
    "            syndrome = np.dot(r, self.H.T) % 2\n",
    "            return np.array2string(syndrome, separator='')[1:-1]\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def decode_message(self, r):\n",
    "        if len(r) == self.n:\n",
    "            syndrome = self.compute_syndrome(r)\n",
    "\n",
    "            if syndrome != '0'*len(syndrome):\n",
    "                error_vector = np.array(self.syndrome_table[syndrome])     # The Error vector is the coset leader linked to the syndrome \n",
    "\n",
    "                print('Error Found!')\n",
    "                print(f'Syndrome: {syndrome}')\n",
    "                print(f'Error Vector: {error_vector}')\n",
    "\n",
    "                if np.count_nonzero(error_vector) > self.correction_thershold:\n",
    "                    print(f'Error correction not possible. Only {self.correction_thershold} error(s) can be corrected.')\n",
    "                    return\n",
    "                else:\n",
    "                    r = (r + self.syndrome_table[syndrome]) % 2    # The error can be corrected by adding the error vector to the message\n",
    "                    print(f'Corrected codeword: {r}')\n",
    "            else:\n",
    "                print('No errors detected.')\n",
    "            \n",
    "            print(f\"Decoded message: {r[:self.k]}\")\n",
    "\n",
    "        else:\n",
    "            print('Error detected: Wrong message length')\n",
    "    \n",
    "\n",
    "    def encode_message(self, message):\n",
    "        if len(message) == self.k:\n",
    "            return np.dot(message, self.G)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetition code-(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors1 = [[1,1,1,1,1], [0,0,0,0,0]]\n",
    "linear_code_1 = LinearCode(vectors1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Matrix\n",
      "[[1 1 1 1 1]]\n",
      "\n",
      "Parity Check Matrix\n",
      "[[1 1 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [1 0 0 1 0]\n",
      " [1 0 0 0 1]]\n",
      "\n",
      "Minimum Hamming Distance\n",
      "5\n",
      "\n",
      "H * G^T\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator Matrix\")\n",
    "print(linear_code_1.G)\n",
    "\n",
    "print(\"\\nParity Check Matrix\")\n",
    "print(linear_code_1.H)\n",
    "\n",
    "print(\"\\nMinimum Hamming Distance\")\n",
    "print(linear_code_1.d)\n",
    "\n",
    "print(\"\\nH * G^T\")\n",
    "print(np.matmul(linear_code_1.H, linear_code_1.G.T) % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coset Table\n",
      "{'0000': [[0, 0, 0, 0, 0], [1, 1, 1, 1, 1]],\n",
      " '0001': [[0, 0, 0, 0, 1], [1, 1, 1, 1, 0]],\n",
      " '0010': [[0, 0, 0, 1, 0], [1, 1, 1, 0, 1]],\n",
      " '0011': [[0, 0, 0, 1, 1], [1, 1, 1, 0, 0]],\n",
      " '0100': [[0, 0, 1, 0, 0], [1, 1, 0, 1, 1]],\n",
      " '0101': [[0, 0, 1, 0, 1], [1, 1, 0, 1, 0]],\n",
      " '0110': [[0, 0, 1, 1, 0], [1, 1, 0, 0, 1]],\n",
      " '0111': [[0, 0, 1, 1, 1], [1, 1, 0, 0, 0]],\n",
      " '1000': [[0, 1, 0, 0, 0], [1, 0, 1, 1, 1]],\n",
      " '1001': [[0, 1, 0, 0, 1], [1, 0, 1, 1, 0]],\n",
      " '1010': [[0, 1, 0, 1, 0], [1, 0, 1, 0, 1]],\n",
      " '1011': [[0, 1, 0, 1, 1], [1, 0, 1, 0, 0]],\n",
      " '1100': [[0, 1, 1, 0, 0], [1, 0, 0, 1, 1]],\n",
      " '1101': [[0, 1, 1, 0, 1], [1, 0, 0, 1, 0]],\n",
      " '1110': [[0, 1, 1, 1, 0], [1, 0, 0, 0, 1]],\n",
      " '1111': [[0, 1, 1, 1, 1], [1, 0, 0, 0, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Coset Table\")\n",
    "pprint.pprint(linear_code_1.coset_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syndrome Table (Syndromes mapped to Coset Leaders)\n",
      "{'0000': [0, 0, 0, 0, 0],\n",
      " '0001': [0, 0, 0, 0, 1],\n",
      " '0010': [0, 0, 0, 1, 0],\n",
      " '0011': [0, 0, 0, 1, 1],\n",
      " '0100': [0, 0, 1, 0, 0],\n",
      " '0101': [0, 0, 1, 0, 1],\n",
      " '0110': [0, 0, 1, 1, 0],\n",
      " '0111': [1, 1, 0, 0, 0],\n",
      " '1000': [0, 1, 0, 0, 0],\n",
      " '1001': [0, 1, 0, 0, 1],\n",
      " '1010': [0, 1, 0, 1, 0],\n",
      " '1011': [1, 0, 1, 0, 0],\n",
      " '1100': [0, 1, 1, 0, 0],\n",
      " '1101': [1, 0, 0, 1, 0],\n",
      " '1110': [1, 0, 0, 0, 1],\n",
      " '1111': [1, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print('Syndrome Table (Syndromes mapped to Coset Leaders)')\n",
    "pprint.pprint(linear_code_1.syndrome_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Codewords\n",
      "[[0 0 0 0 0]\n",
      " [1 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid Codewords\")\n",
    "print(linear_code_1.generate_codewords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Found!\n",
      "Syndrome: 1001\n",
      "Error Vector: [0 1 0 0 1]\n",
      "Corrected codeword: [0 0 0 0 0]\n",
      "Decoded message: [0]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([0,1,0,0,1])\n",
    "linear_code_1.decode_message(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected.\n",
      "Decoded message: [1]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([1,1,1,1,1])\n",
    "linear_code_1.decode_message(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors2 = [[1,0,1,1,0], [0,1,1,1,1]]\n",
    "linear_code_2 = LinearCode(vectors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Matrix\n",
      "[[1 0 1 1 0]\n",
      " [0 1 1 1 1]]\n",
      "\n",
      "Parity Check Matrix\n",
      "[[1 1 1 0 0]\n",
      " [1 1 0 1 0]\n",
      " [0 1 0 0 1]]\n",
      "\n",
      "Minimum Hamming Distance\n",
      "3\n",
      "\n",
      "H * G^T\n",
      "[[0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator Matrix\")\n",
    "print(linear_code_2.G)\n",
    "\n",
    "print(\"\\nParity Check Matrix\")\n",
    "print(linear_code_2.H)\n",
    "\n",
    "print(\"\\nMinimum Hamming Distance\")\n",
    "print(linear_code_2.d)\n",
    "\n",
    "print(\"\\nH * G^T\")\n",
    "print(np.matmul(linear_code_2.H, linear_code_2.G.T) % 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coset Table\n",
      "{'000': [[0, 0, 0, 0, 0], [0, 1, 1, 1, 1], [1, 0, 1, 1, 0], [1, 1, 0, 0, 1]],\n",
      " '001': [[0, 0, 0, 0, 1], [0, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 0, 0]],\n",
      " '010': [[0, 0, 0, 1, 0], [0, 1, 1, 0, 1], [1, 0, 1, 0, 0], [1, 1, 0, 1, 1]],\n",
      " '011': [[0, 0, 0, 1, 1], [0, 1, 1, 0, 0], [1, 0, 1, 0, 1], [1, 1, 0, 1, 0]],\n",
      " '100': [[0, 0, 1, 0, 0], [0, 1, 0, 1, 1], [1, 0, 0, 1, 0], [1, 1, 1, 0, 1]],\n",
      " '101': [[0, 0, 1, 0, 1], [0, 1, 0, 1, 0], [1, 0, 0, 1, 1], [1, 1, 1, 0, 0]],\n",
      " '110': [[0, 0, 1, 1, 0], [0, 1, 0, 0, 1], [1, 0, 0, 0, 0], [1, 1, 1, 1, 1]],\n",
      " '111': [[0, 0, 1, 1, 1], [0, 1, 0, 0, 0], [1, 0, 0, 0, 1], [1, 1, 1, 1, 0]]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Coset Table\")\n",
    "pprint.pprint(linear_code_2.coset_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syndrome Table (Syndromes mapped to Coset Leaders)\n",
      "{'000': [0, 0, 0, 0, 0],\n",
      " '001': [0, 0, 0, 0, 1],\n",
      " '010': [0, 0, 0, 1, 0],\n",
      " '011': [0, 0, 0, 1, 1],\n",
      " '100': [0, 0, 1, 0, 0],\n",
      " '101': [0, 0, 1, 0, 1],\n",
      " '110': [1, 0, 0, 0, 0],\n",
      " '111': [0, 1, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print('Syndrome Table (Syndromes mapped to Coset Leaders)')\n",
    "pprint.pprint(linear_code_2.syndrome_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Codewords\n",
      "[[0 0 0 0 0]\n",
      " [0 1 1 1 1]\n",
      " [1 0 1 1 0]\n",
      " [1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Valid Codewords\")\n",
    "print(linear_code_2.generate_codewords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Found!\n",
      "Syndrome: 110\n",
      "Error Vector: [1 0 0 0 0]\n",
      "Corrected codeword: [1 1 0 0 1]\n",
      "Decoded message: [1 1]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([0,1,0,0,1])\n",
    "linear_code_2.decode_message(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Found!\n",
      "Syndrome: 101\n",
      "Error Vector: [0 0 1 0 1]\n",
      "Error correction not possible. Only 1 error(s) can be corrected.\n"
     ]
    }
   ],
   "source": [
    "r = np.array([0,0,1,0,1])\n",
    "linear_code_2.decode_message(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected.\n",
      "Decoded message: [0 1]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([0,1,1,1,1])\n",
    "linear_code_2.decode_message(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors3 = [\n",
    "    [1,1,1,0,0,0,0],\n",
    "    [1,0,0,1,1,0,0],\n",
    "    [0,1,0,1,0,1,0],\n",
    "    [1,1,0,1,0,0,1]\n",
    "]\n",
    "\n",
    "linear_code_3 = LinearCode(vectors3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000': [0, 0, 0, 0, 0, 0, 0],\n",
       " '001': [0, 0, 0, 0, 0, 0, 1],\n",
       " '010': [0, 0, 0, 0, 0, 1, 0],\n",
       " '011': [1, 0, 0, 0, 0, 0, 0],\n",
       " '100': [0, 0, 0, 0, 1, 0, 0],\n",
       " '101': [0, 1, 0, 0, 0, 0, 0],\n",
       " '110': [0, 0, 1, 0, 0, 0, 0],\n",
       " '111': [0, 0, 0, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_code_3.syndrome_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_code_3.correction_thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_code_3.generate_codewords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Found!\n",
      "Syndrome: 111\n",
      "Error Vector: [0 0 0 1 0 0 0]\n",
      "Corrected codeword: [1 0 1 0 1 0 1]\n",
      "Decoded message: [1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "r = np.array([1,0,1,1,1,0,1])\n",
    "linear_code_3.decode_message(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
